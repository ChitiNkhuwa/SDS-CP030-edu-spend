{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EduSpend CP#30: Global Higher-Education Cost Analytics & Planning\n",
    "Model Comparison Provided by Cursor\n",
    "\n",
    "This code compares the performance of different models on a dataset related to global higher-education costs.  \n",
    "The dataset is assumed to be preprocessed and available as 'edu_cost_data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset, Total Cost of Attendance\n",
    "edu_cost_data = pd.read_csv('../data/TCA_no_outliers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target variable\n",
    "X = edu_cost_data.drop('TCA', axis=1)\n",
    "y = edu_cost_data['TCA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Feature Engineering: Low, Medium, High TCA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TCA tiers based on training data quantiles\n",
    "tca_quantiles = y_train.quantile([0.33, 0.67])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCA Tier Boundaries (based on training data):\n",
      "Low, 33rd percentile: < $27,008\n",
      "Medium, 33rd - 67th percentile: $27,008 - $62,960\n",
      "High, 67th percentile: > $62,960\n"
     ]
    }
   ],
   "source": [
    "# Define tier boundaries based on training data quantiles\n",
    "train_tca_tiers = pd.cut(y_train, bins=[0, tca_quantiles[0.33], tca_quantiles[0.67], float('inf')],\n",
    "                     labels=['Low', 'Medium', 'High'])\n",
    "test_tca_tiers = pd.cut(y_test, bins=[0, tca_quantiles[0.33], tca_quantiles[0.67], float('inf')],\n",
    "                    labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "print(f\"TCA Tier Boundaries (based on training data):\")\n",
    "print(f\"Low, 33rd percentile: < ${tca_quantiles[0.33]:,.0f}\")\n",
    "print(f\"Medium, 33rd - 67th percentile: ${tca_quantiles[0.33]:,.0f} - ${tca_quantiles[0.67]:,.0f}\")\n",
    "print(f\"High, 67th percentile: > ${tca_quantiles[0.67]:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tiers to your feature sets\n",
    "X_train['TCA_Tier'] = train_tca_tiers\n",
    "X_test['TCA_Tier'] = test_tca_tiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TCA tiers to numerical order\n",
    "# Define categories in the correct order: 0, 1, 2\n",
    "categories = [['Low', 'Medium', 'High']]  # Note: nested list\n",
    "\n",
    "oe = OrdinalEncoder(categories=categories)\n",
    "X_train['TCA_Tier_Encoded'] = oe.fit_transform(X_train[['TCA_Tier']])\n",
    "X_test['TCA_Tier_Encoded'] = oe.transform(X_test[['TCA_Tier']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode Level (degree) types\n",
    "level_dummies = pd.get_dummies(X_train['Level'], prefix='Level')\n",
    "X_train = pd.concat([X_train, level_dummies], axis=1)\n",
    "\n",
    "level_dummies_test = pd.get_dummies(X_test['Level'], prefix='Level')\n",
    "X_test = pd.concat([X_test, level_dummies_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'category_encoders'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Using Target Encoding due to high number of unique universities, cities, and countries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcategory_encoders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TargetEncoder\n\u001b[32m      4\u001b[39m categorical_cols = [\u001b[33m'\u001b[39m\u001b[33mCity\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mUniversity\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCountry\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mProgram\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m encoder = TargetEncoder(cols=categorical_cols)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'category_encoders'"
     ]
    }
   ],
   "source": [
    "# Using Target Encoding due to high number of unique universities, cities, and countries\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "categorical_cols = ['City', 'University', 'Country', 'Program']\n",
    "encoder = TargetEncoder(cols=categorical_cols)\n",
    "\n",
    "# Fit on training data only\n",
    "X_train_encoded = encoder.fit_transform(X_train[categorical_cols], y_train)\n",
    "X_test_encoded = encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "# Add encoded columns\n",
    "X_train = pd.concat([X_train, X_train_encoded], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_encoded], axis=1)\n",
    "\n",
    "# Drop original categorical columns\n",
    "X_train = X_train.drop(categorical_cols, axis=1)\n",
    "X_test = X_test.drop(categorical_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Support Vector Regressor': SVR()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Mean Squared Error': mse,\n",
    "        'R^2 Score': r2\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n",
    "```\n",
    "This code snippet loads a dataset related to global higher-education costs, splits it into training and testing sets, \n",
    "trains three different regression models (Linear Regression, Random Forest, and Support Vector Regressor), \n",
    "evaluates their performance using Mean Squared Error and R^2 Score, and finally displays the results in a DataFrame format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SDS-CP026-env)",
   "language": "python",
   "name": "sds-cp026-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
